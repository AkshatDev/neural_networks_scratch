{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R11fENFBl8L"
   },
   "source": [
    "Things to know before -\n",
    "\n",
    "This is Logistic Regression from scratch. This is done and implemented in a way that this can easily be extended to Neural Networks.\n",
    "\n",
    "For now, we can assume this to be a single Neuron with one output.\n",
    "\n",
    "Formulas -\n",
    "\n",
    "Compact form -\n",
    "\n",
    "z = w.T X + b -> a = sigmoid(z) -> Loss l(a,y) = - [y * log(a) + (1-y) * log(1-a)]\n",
    "\n",
    "Our goal - Find optimal w* and b* that minimizes the Loss.\n",
    "\n",
    "Disclamer- We can write the whole formula in one line,\n",
    "loss(w,b) =  -[ y * log(sigmoid(w.T X + b)) + (1-y) - log(1-sigmoid(w.T X+ b))]\n",
    "We can minimize this also, but it gets a bit messy.\n",
    "\n",
    "We are going to use the compact form to keep everything nice and clean.\n",
    "\n",
    "Our goal is to get dl/dz. We can achieve that by finding dl/da * da/dz (chain rule).\n",
    "\n",
    "dl/da= (a-y)/ a(1-a)\n",
    "\n",
    "da/dz= a * (1-a)\n",
    "\n",
    "=> dl/dz = a-y\n",
    "\n",
    "Now, to update w after each iteration, we need to find dl/dw.\n",
    "\n",
    "dl/dw = dl/dz * dz/dw\n",
    "\n",
    "dz/dw = X\n",
    "\n",
    "=> dl/dw= (a-y)*X\n",
    "\n",
    "similarly update for b- \n",
    "\n",
    "dl/db = dl/dz*dz/db\n",
    "\n",
    "dz/db= 1 \n",
    "\n",
    "dl/db = a-y\n",
    "\n",
    "\n",
    "\n",
    "***********************\n",
    "\n",
    "**final update for all w's, w= 1/n * learning_rate * (a-y) * X**\n",
    "\n",
    "**final update for all b's, w= 1/n * learning_rate * (a-y)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a2vyUZkm9sbF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as m\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LKFrpt_g-Kez"
   },
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "  X,y=make_classification(n_samples=1000,n_features=10,random_state=42) # Generating random data\n",
    "  X=np.concatenate((X,np.ones(X.shape[0]).reshape(X.shape[0],1) ), axis=1)\n",
    "  X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "  lr=0.001\n",
    "  lamb=0.01\n",
    "  #print(X.shape,y.shape)\n",
    "  return X_train, X_test, y_train, y_test,lr,lamb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrfPVxp7-117"
   },
   "source": [
    "We have 1000 samples with each sample having 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZaedLyKR_bwu"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  a=1 / ( 1 + np.exp(-(z) ) ) \n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-Eili3FNonH1"
   },
   "outputs": [],
   "source": [
    "def forward_prop(w,X):\n",
    "  return sigmoid( w.T.dot(X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iCsKuXxKAWuB"
   },
   "outputs": [],
   "source": [
    "def back_prop(X,a,y):\n",
    "  dw = np.dot(X,(a-y))\n",
    "  return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LSTsQC1NJvTr"
   },
   "outputs": [],
   "source": [
    "def initialize_params(X):\n",
    "  w=np.zeros(X.shape[1])\n",
    "  #b=np.ones(X.shape[0])\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zPtfkWJUAsQm"
   },
   "outputs": [],
   "source": [
    "def loss(y, y_hat):\n",
    "    loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat)) + lamb * w**2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2zUufh2nLWPu"
   },
   "outputs": [],
   "source": [
    "def predict(w,X):\n",
    "  return sigmoid( w.T.dot(X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_b3vIQvcUZAu"
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "  X_train, X_test, y_train, y_test,lr,lamb=generate_data()\n",
    "  w=initialize_params(X_train)\n",
    "  w=w.T\n",
    "  X_train=X_train.T\n",
    "  X_test=X_test.T\n",
    "  y_train=y_train.T\n",
    "  y_test=X_test.T  \n",
    "\n",
    "  lo=[]\n",
    "  accuracy=[]\n",
    "  for i in range(0,1000):\n",
    "    predictions=[]\n",
    "    a=forward_prop(w,X_train)\n",
    "    dw=back_prop(X_train,a,y_train)\n",
    "    w[0:10]= ((w[0:10] - ( lr * (dw[0:10]) )   ) + lamb* w[0:10] )/X_train.shape[0]\n",
    "    w[10:11]=((w[10:11] - ( lr * (dw[10:11]) )   ) )/X_train.shape[0]\n",
    "    for i in a:\n",
    "      predictions.append(1 if i>=0.5 else 0)\n",
    "    lo.append(loss(y_train,a))\n",
    "    accuracy.append(m.accuracy_score(y_train,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCuUFjofLfWb",
    "outputId": "d3141cdf-69de-4e7b-d467-a832946e5791"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[1;32m      4\u001b[0m   predictions_test\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc on test set\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpredictions_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "a=predict(w,X_test)\n",
    "predictions_test=[]\n",
    "for i in a:\n",
    "  predictions_test.append(1 if i>=0.5 else 0)\n",
    "print('acc on test set',m.accuracy_score(y_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rob07zwYGIf6",
    "outputId": "29190291-b082-469e-99e3-eb088334f927"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [11, 670]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m clf\u001b[38;5;241m=\u001b[39mLogisticRegression()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m preds\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msklearn accuracy on test\u001b[39m\u001b[38;5;124m'\u001b[39m,m\u001b[38;5;241m.\u001b[39maccuracy_score(y_test,preds))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:981\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    964\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    976\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[1;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m--> 981\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    335\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [11, 670]"
     ]
    }
   ],
   "source": [
    "clf=LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "preds=clf.predict(X_test)\n",
    "print('sklearn accuracy on test',m.accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.74030596,  0.42548993,  0.6039124 , ..., -0.98264957,\n",
       "        -1.3716737 ,  1.        ],\n",
       "       [-1.49577819,  0.38135283, -1.2763343 , ...,  1.80201193,\n",
       "        -0.63014283,  1.        ],\n",
       "       [-0.14407863, -0.00928856,  0.02366179, ...,  0.65257238,\n",
       "         1.8134077 ,  1.        ],\n",
       "       ...,\n",
       "       [-1.67945551,  0.47314545, -1.40250885, ...,  2.12312866,\n",
       "        -0.23780704,  1.        ],\n",
       "       [-0.50417344, -0.36861937, -0.45662085, ...,  0.52109091,\n",
       "         1.11968778,  1.        ],\n",
       "       [ 0.30714244,  0.74661136,  0.45012969, ...,  0.24438526,\n",
       "         2.27582543,  1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic_Regression_From_Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
